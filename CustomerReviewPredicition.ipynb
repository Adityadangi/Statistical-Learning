{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing important libraries, reading the data from the disk and then cleaning it so that it can be fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', delimiter='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11755</td>\n",
       "      <td>After reading mixed reviews I almost didn't bo...</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33912</td>\n",
       "      <td>This motor inn is located about - city blocks ...</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10143</td>\n",
       "      <td>It was our first time there and surely not our...</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33114</td>\n",
       "      <td>Great hotel in an excellent location, just off...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17464</td>\n",
       "      <td>We stayed at the hotel for - weeks to get away...</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34367</td>\n",
       "      <td>Myself and two girlfriends were in NYC for - n...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14524</td>\n",
       "      <td>I made last minute reservation and couldnt fin...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35130</td>\n",
       "      <td>Stayed at this hotel for - week. Very nice hot...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1004</td>\n",
       "      <td>My wife and I stayed in the Michelangelo for -...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27086</td>\n",
       "      <td>My wife and I stayed their after a business me...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0    11755  After reading mixed reviews I almost didn't bo...   \n",
       "1    33912  This motor inn is located about - city blocks ...   \n",
       "2    10143  It was our first time there and surely not our...   \n",
       "3    33114  Great hotel in an excellent location, just off...   \n",
       "4    17464  We stayed at the hotel for - weeks to get away...   \n",
       "5    34367  Myself and two girlfriends were in NYC for - n...   \n",
       "6    14524  I made last minute reservation and couldnt fin...   \n",
       "7    35130  Stayed at this hotel for - week. Very nice hot...   \n",
       "8     1004  My wife and I stayed in the Michelangelo for -...   \n",
       "9    27086  My wife and I stayed their after a business me...   \n",
       "\n",
       "       Browser_Used Device_Used Is_Response  \n",
       "0     Google Chrome     Desktop        Good  \n",
       "1           Firefox      Tablet        Good  \n",
       "2     Google Chrome      Mobile        Good  \n",
       "3           Mozilla     Desktop        Good  \n",
       "4     Google Chrome     Desktop        Good  \n",
       "5  InternetExplorer      Mobile        Good  \n",
       "6              Edge     Desktop         Bad  \n",
       "7  InternetExplorer      Mobile         Bad  \n",
       "8  InternetExplorer     Desktop        Good  \n",
       "9  InternetExplorer     Desktop        Good  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To analyse the response we majorly need Description , so we will define our feature matrix with Description and for label we will take Is_Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responses = df['Description']\n",
    "label = df['Is_Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"After reading mixed reviews I almost didn't book at the W, but I was attending a\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0][0:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to print data \n",
    "def print_data_response(record):\n",
    "    print(label[record], \"-->\\t\", responses[record][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good -->\t It was our first time there and surely not our last. Arrived very early off the train and went there\n",
      "Good -->\t Myself and two girlfriends were in NYC for - night for both business and fun! We impressed right off\n",
      "Bad -->\t Stayed at this hotel for - week. Very nice hotel, rooms were nice, beds were good. There is only two\n",
      "Good -->\t My mom and I stayed here for - nights on a short vacation to Seattle and were extremely happy with o\n",
      "Good -->\t This was a great place to end our vacation. We arrived well before check-in time but were immediatel\n",
      "Good -->\t This hotel is sooo very close to the Opera House.\n",
      "You can catch a cab to anywhere-they are always go\n",
      "Good -->\t I always stay at -- Park Ave Hotel when I travel to NY on business (or for any reason). The hotel is\n",
      "Bad -->\t Arrived around -pm. Prepaid through Priceline for a room with - double beds. They said they had noth\n",
      "Bad -->\t Had the opportunity to stay at the Herbert Hotel.... should of passed it up!! Room was o.k.. First o\n",
      "Good -->\t Hotel was nice. Climate control was off, it was cooler in the hallway which had central core between\n",
      "Bad -->\t I like courtyards, but as Marriott Platinum they should have at least a free continental breakfast o\n"
     ]
    }
   ],
   "source": [
    "check_list = [2,5,7,10,23,34,65,77,66,98,100] # randomly checking the data\n",
    "for i in check_list:\n",
    "    print_data_response(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#label = [1 if x =='Good' else 0 for x in label]\n",
    "label = label.tolist()\n",
    "responses = responses.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = [':', \"(\", \")\", \"-\", \".\", \"\\n\", \",\"]\n",
    "\n",
    "for m,i in enumerate(responses):\n",
    "    for j in noise:\n",
    "        responses[m] = responses[m].replace(j,\" \")\n",
    "    responses[m] = responses[m].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good -->\t it was our first time there and surely not our last  arrived very early off the train and went there\n",
      "Good -->\t myself and two girlfriends were in nyc for   night for both business and fun! we impressed right off\n",
      "Bad -->\t stayed at this hotel for   week  very nice hotel  rooms were nice  beds were good  there is only two\n",
      "Good -->\t my mom and i stayed here for   nights on a short vacation to seattle and were extremely happy with o\n",
      "Good -->\t this was a great place to end our vacation  we arrived well before check in time but were immediatel\n",
      "Good -->\t this hotel is sooo very close to the opera house  you can catch a cab to anywhere they are always go\n",
      "Good -->\t i always stay at    park ave hotel when i travel to ny on business  or for any reason   the hotel is\n",
      "Bad -->\t arrived around  pm  prepaid through priceline for a room with   double beds  they said they had noth\n",
      "Bad -->\t had the opportunity to stay at the herbert hotel     should of passed it up!! room was o k   first o\n",
      "Good -->\t hotel was nice  climate control was off  it was cooler in the hallway which had central core between\n",
      "Bad -->\t i like courtyards  but as marriott platinum they should have at least a free continental breakfast o\n"
     ]
    }
   ],
   "source": [
    "for i in check_list:\n",
    "    print_data_response(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving a theory and correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_count = Counter()\n",
    "bad_count = Counter()\n",
    "total_count = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(label)):\n",
    "    if label[i] == \"Good\":\n",
    "        for word in responses[i].split(\" \"):\n",
    "            good_count[word] += 1\n",
    "            total_count[word] += 1\n",
    "    else:\n",
    "        for word in responses[i].split(\" \"):\n",
    "            bad_count[word] += 1\n",
    "            total_count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 451513),\n",
       " ('the', 191563),\n",
       " ('and', 110328),\n",
       " ('a', 87546),\n",
       " ('to', 72853),\n",
       " ('was', 64016),\n",
       " ('in', 48305),\n",
       " ('i', 45407),\n",
       " ('we', 42683),\n",
       " ('of', 40546),\n",
       " ('is', 38480),\n",
       " ('for', 35784),\n",
       " ('hotel', 35248),\n",
       " ('it', 28361),\n",
       " ('room', 26966),\n",
       " ('very', 24038),\n",
       " ('at', 23782),\n",
       " ('with', 23210),\n",
       " ('were', 22357),\n",
       " ('but', 21255)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_count.most_common()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 283006),\n",
       " ('the', 120457),\n",
       " ('and', 55716),\n",
       " ('a', 49468),\n",
       " ('to', 49331),\n",
       " ('was', 40227),\n",
       " ('i', 36418),\n",
       " ('in', 30761),\n",
       " ('of', 24533),\n",
       " ('we', 24230),\n",
       " ('for', 21944),\n",
       " ('room', 20673),\n",
       " ('it', 20368),\n",
       " ('is', 20311),\n",
       " ('hotel', 19311),\n",
       " ('that', 16952),\n",
       " ('not', 15989),\n",
       " ('but', 15112),\n",
       " ('on', 14672),\n",
       " ('at', 14650)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_count.most_common()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_to_bad_ratio = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word,count in total_count.most_common():\n",
    "    if count>100:\n",
    "        ratio = good_count[word]/float(bad_count[word]+1)\n",
    "        good_to_bad_ratio[word] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spotlessly', 21.333333333333332),\n",
       " ('hesitate', 19.23076923076923),\n",
       " ('exceeded', 15.909090909090908),\n",
       " ('spotless', 15.56),\n",
       " ('immaculate', 14.357142857142858),\n",
       " ('delightful', 13.583333333333334),\n",
       " ('back!', 13.333333333333334),\n",
       " ('perfect!', 12.5),\n",
       " ('bryant', 12.5),\n",
       " ('beautifully', 11.8),\n",
       " ('wonderfully', 11.5),\n",
       " ('highly', 11.436507936507937),\n",
       " ('hesitation', 10.727272727272727),\n",
       " ('loved', 10.581151832460733),\n",
       " ('amazing!', 10.5),\n",
       " ('delicious', 10.377358490566039),\n",
       " ('recommending', 10.333333333333334),\n",
       " ('gem', 10.277777777777779),\n",
       " ('welcomed', 10.222222222222221),\n",
       " ('ferry', 9.722222222222221)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_to_bad_ratio.most_common()[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With the help of these ratios we can check the words occuring in the good and bad response and provide them score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets Check that score for some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check For Good Response/Description\n",
      "\n",
      "Ratio for word 'great'  4.695397244209909\n",
      "Ratio for word 'perfect'  9.522058823529411\n",
      "Ratio for word 'delightful'  13.583333333333334\n",
      "Ratio for word 'amazing'  7.751269035532995\n",
      "Ratio for word 'spotlessly'  21.333333333333332\n",
      "\n",
      "Check For Bad Response/Description\n",
      "\n",
      "Ratio for word 'refund'  0.10762331838565023\n",
      "Ratio for word 'filthy'  0.048582995951417005\n",
      "Ratio for word 'worst'  0.1059190031152648\n",
      "Ratio for word 'unacceptable'  0.19791666666666666\n",
      "Ratio for word 'disgusting'  0.04484304932735426\n"
     ]
    }
   ],
   "source": [
    "print(\"Check For Good Response/Description\\n\")\n",
    "print(\"Ratio for word 'great' \",good_to_bad_ratio['great'] )\n",
    "print(\"Ratio for word 'perfect' \",good_to_bad_ratio['perfect'] )\n",
    "print(\"Ratio for word 'delightful' \",good_to_bad_ratio['delightful'] )\n",
    "print(\"Ratio for word 'amazing' \",good_to_bad_ratio['amazing'] )\n",
    "print(\"Ratio for word 'spotlessly' \",good_to_bad_ratio['spotlessly'] )\n",
    "####------------------------------------------------------------------####\n",
    "print(\"\\nCheck For Bad Response/Description\\n\")\n",
    "print(\"Ratio for word 'refund' \",good_to_bad_ratio['refund'] )\n",
    "print(\"Ratio for word 'filthy' \",good_to_bad_ratio['filthy'] )\n",
    "print(\"Ratio for word 'worst' \",good_to_bad_ratio['worst'] )\n",
    "print(\"Ratio for word 'unacceptable' \",good_to_bad_ratio['unacceptable'] )\n",
    "print(\"Ratio for word 'disgusting' \",good_to_bad_ratio['disgusting'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see we have a really low score for negative words and high for positive. We can further clear this by taking log values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = good_to_bad_ratio.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_val = list(values)[0]\n",
    "for i in list(values):\n",
    "    if i >0 and i < min_val:\n",
    "        min_val = i\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word, ratio in good_to_bad_ratio.most_common():\n",
    "    if ratio <= 0 :\n",
    "        good_to_bad_ratio[word] = min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, ratio in good_to_bad_ratio.most_common():\n",
    "    good_to_bad_ratio[word] = np.log(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check For Good Response/Description\n",
      "\n",
      "Ratio for word 'great'  1.54658271914\n",
      "Ratio for word 'perfect'  2.2536110884\n",
      "Ratio for word 'delightful'  2.60884355102\n",
      "Ratio for word 'amazing'  2.04785657648\n",
      "Ratio for word 'spotlessly'  3.06027079469\n",
      "\n",
      "Check For Bad Response/Description\n",
      "\n",
      "Ratio for word 'refund'  -2.22911794111\n",
      "Ratio for word 'filthy'  -3.02448168684\n",
      "Ratio for word 'worst'  -2.24508059851\n",
      "Ratio for word 'unacceptable'  -1.6199092123\n",
      "Ratio for word 'disgusting'  -3.10458667847\n"
     ]
    }
   ],
   "source": [
    "print(\"Check For Good Response/Description\\n\")\n",
    "print(\"Ratio for word 'great' \",good_to_bad_ratio['great'] )\n",
    "print(\"Ratio for word 'perfect' \",good_to_bad_ratio['perfect'] )\n",
    "print(\"Ratio for word 'delightful' \",good_to_bad_ratio['delightful'] )\n",
    "print(\"Ratio for word 'amazing' \",good_to_bad_ratio['amazing'] )\n",
    "print(\"Ratio for word 'spotlessly' \",good_to_bad_ratio['spotlessly'] )\n",
    "####------------------------------------------------------------------####\n",
    "print(\"\\nCheck For Bad Response/Description\\n\")\n",
    "print(\"Ratio for word 'refund' \",good_to_bad_ratio['refund'] )\n",
    "print(\"Ratio for word 'filthy' \",good_to_bad_ratio['filthy'] )\n",
    "print(\"Ratio for word 'worst' \",good_to_bad_ratio['worst'] )\n",
    "print(\"Ratio for word 'unacceptable' \",good_to_bad_ratio['unacceptable'] )\n",
    "print(\"Ratio for word 'disgusting' \",good_to_bad_ratio['disgusting'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can clearly see the negative values for the words mostly occuring in bad response and positive for good. We can now hopefully derive such relations while building model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will try to define a structure on which we will be building our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will get the vocab size, define the layer with that size and then fill the index related to the word with one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(total_count.keys())\n",
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0 = np.zeros((1,vocab_size))\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'emerge': 1,\n",
       " 'face\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 2,\n",
       " 'com': 3,\n",
       " 'prius': 4,\n",
       " 'divan': 5,\n",
       " \"mimosa's\": 6,\n",
       " 'roger': 7,\n",
       " 'mornng': 8,\n",
       " 'tortuerous': 9,\n",
       " 'gimlet!': 10,\n",
       " 'cruel': 11,\n",
       " 'vantage': 12,\n",
       " 'fiancial': 13,\n",
       " 'faintest': 14,\n",
       " 'fooling': 15,\n",
       " 'fierce': 16,\n",
       " 'choicehotel': 17,\n",
       " \"day'\": 18,\n",
       " 'manning': 19,\n",
       " 'keneshia': 20,\n",
       " 'need?': 21,\n",
       " 'yaaaaay!!': 22,\n",
       " 'unrestful': 23,\n",
       " \"vehicles'\": 24,\n",
       " \"traveler's\": 25,\n",
       " 'exagerated': 26,\n",
       " 'ponte': 27,\n",
       " 'saff': 28,\n",
       " 'lid!': 29,\n",
       " 'whererever': 30,\n",
       " 'blunds': 31,\n",
       " 'everyone!!': 32,\n",
       " 'celing': 33,\n",
       " 'zipping': 34,\n",
       " 'challange': 35,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"bread': 36,\n",
       " 'exlpain': 37,\n",
       " 'economics': 38,\n",
       " 'inconveniently': 39,\n",
       " 'sercurity': 40,\n",
       " 'smithsonian': 41,\n",
       " 'armchairs': 42,\n",
       " 'elan': 43,\n",
       " \"brittany's\": 44,\n",
       " 'sardines!': 45,\n",
       " 'scandinavians': 46,\n",
       " 'dealership': 47,\n",
       " 'replacment': 48,\n",
       " 'meanest': 49,\n",
       " 'scientology': 50,\n",
       " '*free*': 51,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"braun\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 52,\n",
       " 'insurance!”': 53,\n",
       " 'rental': 54,\n",
       " 'declines': 55,\n",
       " 'happen!': 56,\n",
       " 'hotel?!?': 57,\n",
       " 'celebrants': 58,\n",
       " 'lappy': 59,\n",
       " 'new\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 60,\n",
       " 'bathrobes': 61,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"lounge\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 62,\n",
       " 'rage': 63,\n",
       " 'bathroom?!': 64,\n",
       " 'burgundy': 65,\n",
       " 'down!!!!!': 66,\n",
       " 'trying': 67,\n",
       " 'uhm': 68,\n",
       " 'lather!': 69,\n",
       " \"date'\": 70,\n",
       " 'icrowave': 71,\n",
       " 'wierd': 72,\n",
       " 'choreographed': 73,\n",
       " 'fortune\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 74,\n",
       " 'furniture;': 75,\n",
       " 'infirm': 76,\n",
       " 'scuff': 77,\n",
       " 'loyd': 78,\n",
       " 'fireplaces': 79,\n",
       " 'chooses': 80,\n",
       " 'fodors': 81,\n",
       " 'untensils': 82,\n",
       " 'mme': 83,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"screaming': 84,\n",
       " 'reveled': 85,\n",
       " 'you’ll': 86,\n",
       " 'spackle': 87,\n",
       " 'alledged': 88,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"twilight': 89,\n",
       " 'teach': 90,\n",
       " 'mpd': 91,\n",
       " 'tax!!': 92,\n",
       " 'ncy': 93,\n",
       " 'eastwick': 94,\n",
       " \"'cosy\": 95,\n",
       " 'copying': 96,\n",
       " 'maggiano’s': 97,\n",
       " 'airports!': 98,\n",
       " 'wiil': 99,\n",
       " 'cunduct': 100,\n",
       " 'itslf': 101,\n",
       " 'oo': 102,\n",
       " 'offshore': 103,\n",
       " 'hannah': 104,\n",
       " 'castel': 105,\n",
       " 'tightening': 106,\n",
       " 'ref': 107,\n",
       " 'paddies': 108,\n",
       " 'satisfies': 109,\n",
       " 'gino’s': 110,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"live\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 111,\n",
       " 'torso': 112,\n",
       " 'common!!': 113,\n",
       " 'hiltonhhonors': 114,\n",
       " 'pleasent': 115,\n",
       " 'sliped': 116,\n",
       " 'apples': 117,\n",
       " \"diddy's\": 118,\n",
       " 'tyle': 119,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"distressed\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 120,\n",
       " 'easton': 121,\n",
       " 'silks': 122,\n",
       " 'story': 123,\n",
       " 'redecorating': 124,\n",
       " 'tohave': 125,\n",
       " 'outdoor': 126,\n",
       " 'guides': 127,\n",
       " 'walgreens': 128,\n",
       " 'nitwit': 129,\n",
       " 'oberoi': 130,\n",
       " 'fumes': 131,\n",
       " 'bengals': 132,\n",
       " 'disappated': 133,\n",
       " 'afgans': 134,\n",
       " 'argonaunt': 135,\n",
       " 'recommended!!': 136,\n",
       " 'hitchcock': 137,\n",
       " 'prosecution': 138,\n",
       " 'mam\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 139,\n",
       " 'dtrs': 140,\n",
       " 'starbucks;': 141,\n",
       " 'competent': 142,\n",
       " 'renter': 143,\n",
       " 'showbox': 144,\n",
       " 'traveleled': 145,\n",
       " 'nth': 146,\n",
       " 'digit': 147,\n",
       " 'penney!': 148,\n",
       " 'unprompted': 149,\n",
       " 'tylenol': 150,\n",
       " 'opulence': 151,\n",
       " 'about\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 152,\n",
       " 'havana': 153,\n",
       " 'thingy': 154,\n",
       " 'pretty!': 155,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"bakery': 156,\n",
       " 'splenda': 157,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"indepedent\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 158,\n",
       " 'task': 159,\n",
       " 'outclasses': 160,\n",
       " 'rewards!!': 161,\n",
       " 'twombly': 162,\n",
       " 'awfuls': 163,\n",
       " 'instead!!': 164,\n",
       " \"mann's\": 165,\n",
       " \"paul's\": 166,\n",
       " 'annually': 167,\n",
       " 'trying!': 168,\n",
       " 'suppossed': 169,\n",
       " 'rant': 170,\n",
       " 'smell!': 171,\n",
       " 'glitter': 172,\n",
       " 'dfferent': 173,\n",
       " 'cool\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 174,\n",
       " 'airco': 175,\n",
       " 'hammocks': 176,\n",
       " 'off?\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 177,\n",
       " 'land': 178,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"renovating\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 179,\n",
       " 'isham': 180,\n",
       " 'closed??!!': 181,\n",
       " 'nescessities': 182,\n",
       " 'pacc': 183,\n",
       " 'subdivision': 184,\n",
       " 'card;': 185,\n",
       " 'anton': 186,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"kapow\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 187,\n",
       " 'minds?': 188,\n",
       " 'drinking\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 189,\n",
       " 'anail': 190,\n",
       " \"latte'\": 191,\n",
       " 'intrigued': 192,\n",
       " 'untrimmed': 193,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"serve': 194,\n",
       " 'kitchenette': 195,\n",
       " 'huntington': 196,\n",
       " 'sportsbar!': 197,\n",
       " 'sitiuation': 198,\n",
       " 'feature': 199,\n",
       " 'rumpled': 200,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"taxi': 201,\n",
       " 'tennants': 202,\n",
       " 'blah!': 203,\n",
       " 'glue?': 204,\n",
       " 'magnificence': 205,\n",
       " 'professional;': 206,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"finds\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 207,\n",
       " 'thinking…': 208,\n",
       " 'purchasing': 209,\n",
       " 'strawberrrys': 210,\n",
       " 'duncan': 211,\n",
       " 'babymoon': 212,\n",
       " 'momento': 213,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"uniforms\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 214,\n",
       " 'mistreatment': 215,\n",
       " 'treated!': 216,\n",
       " 'youssuf': 217,\n",
       " 'decant': 218,\n",
       " 'available': 219,\n",
       " 'relabeled': 220,\n",
       " 'tyhe': 221,\n",
       " 'reade': 222,\n",
       " 'ridicules': 223,\n",
       " 'highpoints': 224,\n",
       " 'cab?': 225,\n",
       " 'expectations!': 226,\n",
       " 'snaking': 227,\n",
       " 'via': 228,\n",
       " 'whisper': 229,\n",
       " 'asthmatic': 230,\n",
       " 'stairmasters': 231,\n",
       " 'plaster': 232,\n",
       " 'groundless': 233,\n",
       " 'unmusty': 234,\n",
       " '“permanent': 235,\n",
       " 'categorized': 236,\n",
       " 'whirlwind': 237,\n",
       " 'unmade': 238,\n",
       " 'tubs!': 239,\n",
       " 'withinn': 240,\n",
       " 'hovers': 241,\n",
       " 'county': 242,\n",
       " 'significat': 243,\n",
       " 'minerva': 244,\n",
       " 'roomtoo': 245,\n",
       " 'trollely': 246,\n",
       " 'diligence': 247,\n",
       " 'uncovering': 248,\n",
       " 'incidentially': 249,\n",
       " 'whirlpools': 250,\n",
       " 'elclipses': 251,\n",
       " 'akin': 252,\n",
       " 'lite': 253,\n",
       " 'rockparty': 254,\n",
       " 'must!': 255,\n",
       " 'principle': 256,\n",
       " 'girl\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 257,\n",
       " 'hotells': 258,\n",
       " 'consumption': 259,\n",
       " 'cabbage': 260,\n",
       " 'apolozed': 261,\n",
       " 'siesta': 262,\n",
       " 'unread': 263,\n",
       " 'crazily': 264,\n",
       " 'stowkowsi': 265,\n",
       " 'kc': 266,\n",
       " 'likelihood': 267,\n",
       " 'book!!': 268,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"felt\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 269,\n",
       " 'first;': 270,\n",
       " 'doorman': 271,\n",
       " 'caption': 272,\n",
       " 'ooooh': 273,\n",
       " 'merged': 274,\n",
       " 'bakery': 275,\n",
       " 'clientelle': 276,\n",
       " 'free?': 277,\n",
       " 'tiny!!': 278,\n",
       " 'entranceway': 279,\n",
       " 'newbury': 280,\n",
       " 'lie!!': 281,\n",
       " 'clever': 282,\n",
       " 'caveman': 283,\n",
       " 'unintersted': 284,\n",
       " 'hgihtly': 285,\n",
       " 'almost': 286,\n",
       " 'recommendations!': 287,\n",
       " 'paso': 288,\n",
       " 'clerks;': 289,\n",
       " 'mccaslin': 290,\n",
       " \"tots'\": 291,\n",
       " 'congratulate': 292,\n",
       " 'indices': 293,\n",
       " 'dripping': 294,\n",
       " 'coudlnt': 295,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"four\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 296,\n",
       " 'flusehd': 297,\n",
       " 'wynham': 298,\n",
       " 'specal': 299,\n",
       " 'slovenly': 300,\n",
       " 'prioriity': 301,\n",
       " 'moved!!': 302,\n",
       " 'removable': 303,\n",
       " 'blackouts': 304,\n",
       " 'misprint': 305,\n",
       " 'leafs': 306,\n",
       " 'gare': 307,\n",
       " 'energetic!': 308,\n",
       " 'gump”': 309,\n",
       " 'launder': 310,\n",
       " 'becky': 311,\n",
       " 'postcards': 312,\n",
       " 'gardener': 313,\n",
       " 'recently': 314,\n",
       " 'rodrigo': 315,\n",
       " 'situation!': 316,\n",
       " 'hardys': 317,\n",
       " 'container': 318,\n",
       " 'apologized': 319,\n",
       " 'sales': 320,\n",
       " 'to?\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"the': 321,\n",
       " 'leve': 322,\n",
       " 'bad”': 323,\n",
       " 'chinatown': 324,\n",
       " 'rectified': 325,\n",
       " 'saltimbucca': 326,\n",
       " 'offputting': 327,\n",
       " 'tezelia': 328,\n",
       " 'indicative': 329,\n",
       " 'advertising…': 330,\n",
       " 'milling': 331,\n",
       " 'bowdoin': 332,\n",
       " \"girls'\": 333,\n",
       " 'unreasonable?': 334,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"dip\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 335,\n",
       " 'floor[': 336,\n",
       " 'nary': 337,\n",
       " 'tailbone': 338,\n",
       " 'tap': 339,\n",
       " 'shag': 340,\n",
       " 'dissatisfaction': 341,\n",
       " 'cauzionale': 342,\n",
       " 'didn`t': 343,\n",
       " \"computer's\": 344,\n",
       " 'metrolpolitan': 345,\n",
       " 'wasps': 346,\n",
       " 'faulted!!': 347,\n",
       " 'clarence': 348,\n",
       " 'wardrobe': 349,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"funky\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 350,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"five': 351,\n",
       " 'complimenty': 352,\n",
       " 'inclines!': 353,\n",
       " 'dellies': 354,\n",
       " 'strong!': 355,\n",
       " 'personas': 356,\n",
       " 'speedier': 357,\n",
       " 'frot': 358,\n",
       " 'lightswitch': 359,\n",
       " 'qantas': 360,\n",
       " 'judith': 361,\n",
       " 'itinerary!': 362,\n",
       " 'we`d': 363,\n",
       " 'bot': 364,\n",
       " 'revitalizing': 365,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"goody': 366,\n",
       " 'evidence\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 367,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"friends\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 368,\n",
       " 'conventioners': 369,\n",
       " '***dining': 370,\n",
       " 'shoer': 371,\n",
       " 'siphoned': 372,\n",
       " 'mcarthur': 373,\n",
       " 'mella': 374,\n",
       " 'pleasantt': 375,\n",
       " 'advocate': 376,\n",
       " 'fhr': 377,\n",
       " \"'supershuttle'\": 378,\n",
       " 'ill': 379,\n",
       " 'uneventful': 380,\n",
       " 'estadio': 381,\n",
       " \"francesca's\": 382,\n",
       " 'experienced…anywhere': 383,\n",
       " 'thepersonthat': 384,\n",
       " 'ethic': 385,\n",
       " 'bravisimo': 386,\n",
       " 'seatings': 387,\n",
       " 'mormon': 388,\n",
       " 'use;': 389,\n",
       " 'outside': 390,\n",
       " 'textures': 391,\n",
       " 'cousy': 392,\n",
       " 'hale': 393,\n",
       " \"midwest's\": 394,\n",
       " 'omni!!': 395,\n",
       " 'mile!': 396,\n",
       " 'pored': 397,\n",
       " 'okay!': 398,\n",
       " \"'urrrrrrm'\": 399,\n",
       " 'arrangments': 400,\n",
       " 'bukowski': 401,\n",
       " 'slept!': 402,\n",
       " 'cvery': 403,\n",
       " 'upgraded!': 404,\n",
       " 'commisserated': 405,\n",
       " '***we': 406,\n",
       " 'guy': 407,\n",
       " 'italian': 408,\n",
       " 'top;': 409,\n",
       " \"dana's\": 410,\n",
       " 'phon': 411,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"wicked\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 412,\n",
       " 'properies': 413,\n",
       " 'dedicated': 414,\n",
       " 'straggly': 415,\n",
       " 'hostess!': 416,\n",
       " 'terminal': 417,\n",
       " 'chandon': 418,\n",
       " 'titanic': 419,\n",
       " 'beautitful': 420,\n",
       " 'nesters': 421,\n",
       " 'homestead': 422,\n",
       " 'receieved': 423,\n",
       " 'jewish': 424,\n",
       " 'lilliana': 425,\n",
       " 'patricks': 426,\n",
       " 'hyatt!!!': 427,\n",
       " 'crampped': 428,\n",
       " \"yorker's\": 429,\n",
       " 'flew': 430,\n",
       " 'believe': 431,\n",
       " 'unintimidating': 432,\n",
       " 'occcastion': 433,\n",
       " 'blockaway': 434,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"dream': 435,\n",
       " 'tchatchkes': 436,\n",
       " 'waving': 437,\n",
       " 'pa': 438,\n",
       " \"made'\": 439,\n",
       " 'illustrated': 440,\n",
       " 'deadbolts': 441,\n",
       " 'piggishly': 442,\n",
       " 'gasoline': 443,\n",
       " 'reimbursed': 444,\n",
       " 'int': 445,\n",
       " \"yelp'd\": 446,\n",
       " 'bartending': 447,\n",
       " 'confy': 448,\n",
       " 'allergies!': 449,\n",
       " 'carnelian': 450,\n",
       " 'thefun': 451,\n",
       " 'privately': 452,\n",
       " 'scabbies': 453,\n",
       " 'terminals': 454,\n",
       " 'blâmée': 455,\n",
       " 'airpport': 456,\n",
       " 'becase': 457,\n",
       " 'i': 458,\n",
       " 'vivre\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 459,\n",
       " 'becas': 460,\n",
       " 'elast': 461,\n",
       " 'lapse': 462,\n",
       " 'roast': 463,\n",
       " 'artists': 464,\n",
       " 'nutshell': 465,\n",
       " 'mdx': 466,\n",
       " 'slot': 467,\n",
       " 'sized': 468,\n",
       " 'slurping': 469,\n",
       " 'stophop': 470,\n",
       " 'peed': 471,\n",
       " 'cupcakes?': 472,\n",
       " 'unequipped': 473,\n",
       " 'hotel!!': 474,\n",
       " 'suoer': 475,\n",
       " 'kept': 476,\n",
       " 'songs': 477,\n",
       " 'peachtree': 478,\n",
       " 'bloomindales': 479,\n",
       " 'clarify': 480,\n",
       " \"'ra'\": 481,\n",
       " 'slowish': 482,\n",
       " 'finbal': 483,\n",
       " 'tktmax': 484,\n",
       " 'sheets': 485,\n",
       " '“campers”': 486,\n",
       " 'becca': 487,\n",
       " 'sunrises': 488,\n",
       " 'stopovers': 489,\n",
       " 'reminisent': 490,\n",
       " 'nice!!': 491,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"randolph\\'s': 492,\n",
       " 'spigot': 493,\n",
       " 'hone': 494,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"bing\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 495,\n",
       " 'westwood': 496,\n",
       " 'edna!': 497,\n",
       " 'osha': 498,\n",
       " 'founders': 499,\n",
       " 'excellents': 500,\n",
       " 'altohugh': 501,\n",
       " 'hungarian': 502,\n",
       " 'couiple': 503,\n",
       " 'choce': 504,\n",
       " 'dimming': 505,\n",
       " 'appearence': 506,\n",
       " 'peerfect': 507,\n",
       " 'go!!!!': 508,\n",
       " \"'they\": 509,\n",
       " 'fer': 510,\n",
       " 'jaffe': 511,\n",
       " 'biell': 512,\n",
       " 'backpacked': 513,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"descended\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 514,\n",
       " \"noise'\": 515,\n",
       " 'flesh': 516,\n",
       " 'happened?': 517,\n",
       " 'schoolers': 518,\n",
       " 'done\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 519,\n",
       " 'fantastico': 520,\n",
       " 'revolving': 521,\n",
       " 'his!': 522,\n",
       " 'wastepaper': 523,\n",
       " 'salons': 524,\n",
       " 'tracking': 525,\n",
       " 'daughters’': 526,\n",
       " 'bullhorns': 527,\n",
       " 'reply': 528,\n",
       " 'system\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 529,\n",
       " 'laundrette': 530,\n",
       " 'wasa': 531,\n",
       " \"dump'\": 532,\n",
       " 'clealry': 533,\n",
       " \"'partyer'\": 534,\n",
       " 'bedrs': 535,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"manhattan': 536,\n",
       " 'urging': 537,\n",
       " 'priced”': 538,\n",
       " 'determination': 539,\n",
       " \"teacher's\": 540,\n",
       " 'shirt?': 541,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"active\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 542,\n",
       " 'restruant': 543,\n",
       " 'sexy!': 544,\n",
       " 'aroun': 545,\n",
       " 'goal': 546,\n",
       " 'cathederal': 547,\n",
       " 'muffins!': 548,\n",
       " 'gardening': 549,\n",
       " 'fatgue': 550,\n",
       " 'quasidilla': 551,\n",
       " 'roooms': 552,\n",
       " 'commodity': 553,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"snobsdale\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 554,\n",
       " 'bourne': 555,\n",
       " 'knowles': 556,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"double\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 557,\n",
       " 'flight?': 558,\n",
       " 'unloaded': 559,\n",
       " 'motorcycles': 560,\n",
       " 'froom': 561,\n",
       " 'unreasonable': 562,\n",
       " 'obtrusive;': 563,\n",
       " 'eaters': 564,\n",
       " 'terence': 565,\n",
       " 'standard;': 566,\n",
       " 'adventures!!': 567,\n",
       " 'minty': 568,\n",
       " 'paced': 569,\n",
       " 'pillowcase': 570,\n",
       " 'incredible;': 571,\n",
       " 'sitll': 572,\n",
       " 'miscalculated': 573,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"cozy': 574,\n",
       " 'sit!': 575,\n",
       " 'refer': 576,\n",
       " 'defentely': 577,\n",
       " 'yosemite': 578,\n",
       " 'subparly': 579,\n",
       " 'ago!!!!!!!!': 580,\n",
       " 'knows?': 581,\n",
       " 'svc': 582,\n",
       " 'gradually': 583,\n",
       " 'bedroom\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 584,\n",
       " 'hoboken': 585,\n",
       " 'assest': 586,\n",
       " 'webiste': 587,\n",
       " 'preferential': 588,\n",
       " 'meatless': 589,\n",
       " 'clogged': 590,\n",
       " 'cliche': 591,\n",
       " 'aba': 592,\n",
       " 'panther': 593,\n",
       " 'giard': 594,\n",
       " 'jetlagged': 595,\n",
       " 'cheapened': 596,\n",
       " \"'recharge'\": 597,\n",
       " 'viewpoint': 598,\n",
       " 'sides': 599,\n",
       " 'relaxing;': 600,\n",
       " \"y'know!\": 601,\n",
       " 'requires': 602,\n",
       " 'recommened': 603,\n",
       " 'worry;': 604,\n",
       " 'aerial': 605,\n",
       " 'park!!!': 606,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"decent\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 607,\n",
       " 'instinct': 608,\n",
       " 'comforted': 609,\n",
       " 'alternitive': 610,\n",
       " 'businesspeople': 611,\n",
       " 'keys!': 612,\n",
       " 'visibily': 613,\n",
       " \"language!'\": 614,\n",
       " 'pedicabs': 615,\n",
       " 'bouquets': 616,\n",
       " 'pick': 617,\n",
       " 'notify': 618,\n",
       " 'smellies': 619,\n",
       " 'blue': 620,\n",
       " 'seen;': 621,\n",
       " 'crockpot': 622,\n",
       " 'remodelng': 623,\n",
       " 'pompous!': 624,\n",
       " 'inglewood': 625,\n",
       " 'suns': 626,\n",
       " 'ourthird': 627,\n",
       " 'brendel': 628,\n",
       " \"mulitudes'\": 629,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"managers': 630,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"courtesy\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 631,\n",
       " 'flawed': 632,\n",
       " 'unmentionable': 633,\n",
       " 'alredo': 634,\n",
       " 'impractical': 635,\n",
       " 'lobster': 636,\n",
       " 'where;': 637,\n",
       " 'fingerling': 638,\n",
       " 'bathing': 639,\n",
       " \"'her\": 640,\n",
       " 'perfer': 641,\n",
       " 'van\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 642,\n",
       " '“manager’s': 643,\n",
       " 'gadgets': 644,\n",
       " 'fanuel': 645,\n",
       " 'affordable?': 646,\n",
       " 'colinas': 647,\n",
       " 'recarpet': 648,\n",
       " 'trips': 649,\n",
       " 'pickyou': 650,\n",
       " 'close!': 651,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"completely': 652,\n",
       " 'looney': 653,\n",
       " 'hole': 654,\n",
       " 'angry': 655,\n",
       " 'portholes': 656,\n",
       " 'luckly': 657,\n",
       " 'exept': 658,\n",
       " 'sample': 659,\n",
       " 'drummer!': 660,\n",
       " 'freeweights!the': 661,\n",
       " 'dare!': 662,\n",
       " 'atmo': 663,\n",
       " 'conferance': 664,\n",
       " 'cava': 665,\n",
       " 'doeuvres': 666,\n",
       " \"people's\": 667,\n",
       " 'managament': 668,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"pending': 669,\n",
       " 'bedbugs': 670,\n",
       " '“fluff': 671,\n",
       " 'transits': 672,\n",
       " 'vw': 673,\n",
       " \"who's\": 674,\n",
       " 'bch': 675,\n",
       " 'mandates': 676,\n",
       " 'meets': 677,\n",
       " 'cool!!!': 678,\n",
       " 'fit\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 679,\n",
       " 'loundge': 680,\n",
       " 'sustainer': 681,\n",
       " 'driscoll': 682,\n",
       " 'miti': 683,\n",
       " 'the\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"cafe\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 684,\n",
       " 'lg': 685,\n",
       " 'pandaro': 686,\n",
       " 'deep': 687,\n",
       " 'chesnutstreet': 688,\n",
       " 'closet': 689,\n",
       " \"center's\": 690,\n",
       " 'silverfish': 691,\n",
       " 'vagrent': 692,\n",
       " 'candy': 693,\n",
       " 'yields': 694,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"engineering\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 695,\n",
       " 'whataburger': 696,\n",
       " 'clanging': 697,\n",
       " 'inefficient': 698,\n",
       " 'hoofer': 699,\n",
       " 'sweatshirts': 700,\n",
       " 'expidia': 701,\n",
       " 'hade': 702,\n",
       " 'cold!!': 703,\n",
       " 'apprciated': 704,\n",
       " 'divey': 705,\n",
       " 'roadd': 706,\n",
       " 'how': 707,\n",
       " 'unintentionally': 708,\n",
       " \"'welcome\": 709,\n",
       " \"brendan's\": 710,\n",
       " 'betwwen': 711,\n",
       " 'accessing': 712,\n",
       " 'developments': 713,\n",
       " 'magnificently': 714,\n",
       " 'modern!!': 715,\n",
       " 'redress': 716,\n",
       " 'castings': 717,\n",
       " 'zatinya': 718,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"dave\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 719,\n",
       " 'b&d': 720,\n",
       " 'tired”': 721,\n",
       " 'unpredictable': 722,\n",
       " 'blond': 723,\n",
       " 'puzzling': 724,\n",
       " 'means': 725,\n",
       " 'twitching': 726,\n",
       " 'obh': 727,\n",
       " 'phenomenal!!!!!': 728,\n",
       " 'sweeter': 729,\n",
       " 'couteous': 730,\n",
       " 'keating': 731,\n",
       " 'marv': 732,\n",
       " 'attrations': 733,\n",
       " 'panhandlers': 734,\n",
       " 'legit': 735,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"tropicana': 736,\n",
       " 'borrow!': 737,\n",
       " 'rankings': 738,\n",
       " 'smoothest': 739,\n",
       " 'preakness': 740,\n",
       " 'memorized': 741,\n",
       " 'mission': 742,\n",
       " 'shelburne!!': 743,\n",
       " 'paisely': 744,\n",
       " 'player!': 745,\n",
       " 'stingrays': 746,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"concept': 747,\n",
       " 'click': 748,\n",
       " 'piggied': 749,\n",
       " 'complitely': 750,\n",
       " 'verly': 751,\n",
       " 'traits': 752,\n",
       " 'detectors': 753,\n",
       " 'hight': 754,\n",
       " 'considerations': 755,\n",
       " 'emerges': 756,\n",
       " 'strole': 757,\n",
       " 'inckluded': 758,\n",
       " 'minibar”': 759,\n",
       " 'disparate': 760,\n",
       " 'spray!!!!': 761,\n",
       " 'pirce': 762,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"gee': 763,\n",
       " 'seuss': 764,\n",
       " 'onion': 765,\n",
       " 'hotel!!!!!!': 766,\n",
       " 'estimated': 767,\n",
       " 'overcharge!': 768,\n",
       " 'agnes': 769,\n",
       " 'indication!': 770,\n",
       " 'heresy': 771,\n",
       " 'salgado': 772,\n",
       " 'frustrated!!!': 773,\n",
       " 'attentive;': 774,\n",
       " \"'[\": 775,\n",
       " 'taling': 776,\n",
       " 'ellectrical': 777,\n",
       " 'masterful': 778,\n",
       " 'patrik': 779,\n",
       " 'lm': 780,\n",
       " \"somoeone's\": 781,\n",
       " 'amzing': 782,\n",
       " 'jada': 783,\n",
       " 'marksmen': 784,\n",
       " 'miel': 785,\n",
       " 'goond': 786,\n",
       " 'proportioned': 787,\n",
       " 'interactions\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 788,\n",
       " 'aw': 789,\n",
       " 'rooms?!?!': 790,\n",
       " \"hollywood's\": 791,\n",
       " 'journey\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 792,\n",
       " 'livonia': 793,\n",
       " 'deli\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 794,\n",
       " \"comp'd\": 795,\n",
       " 'superb!': 796,\n",
       " '[a': 797,\n",
       " 'mumbles': 798,\n",
       " 'arterial': 799,\n",
       " 'downtownn': 800,\n",
       " 'stgaff': 801,\n",
       " 'lillies': 802,\n",
       " 'chemicals': 803,\n",
       " 'highway': 804,\n",
       " 'dr': 805,\n",
       " 'california\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 806,\n",
       " 'mabel???': 807,\n",
       " 'endlessly': 808,\n",
       " 'bathrobes!': 809,\n",
       " 'them!and': 810,\n",
       " 'tremont': 811,\n",
       " 'planes': 812,\n",
       " 'chcked': 813,\n",
       " 'sectional': 814,\n",
       " 'hyatt': 815,\n",
       " '“american': 816,\n",
       " 'ceratinly': 817,\n",
       " 'reselect': 818,\n",
       " 'joghurt': 819,\n",
       " 'inward': 820,\n",
       " 'fenced': 821,\n",
       " 'javits': 822,\n",
       " 'waikiki': 823,\n",
       " 'cathedral': 824,\n",
       " 'bothersome—but': 825,\n",
       " 'doom': 826,\n",
       " 'appologize': 827,\n",
       " 'mayflower': 828,\n",
       " 'basically': 829,\n",
       " 'plating': 830,\n",
       " '\\xa0bedside': 831,\n",
       " 'ruffles': 832,\n",
       " 'okay': 833,\n",
       " 'size': 834,\n",
       " 'overcharges': 835,\n",
       " 'sore!!!': 836,\n",
       " 'abundance': 837,\n",
       " 'ourself': 838,\n",
       " 'plaque': 839,\n",
       " 'occasion': 840,\n",
       " 'terrible!!!': 841,\n",
       " 'dmz': 842,\n",
       " 'removing': 843,\n",
       " 'hearts': 844,\n",
       " 'johnathon': 845,\n",
       " 'clipping': 846,\n",
       " 'trois': 847,\n",
       " 'cosmopolitan': 848,\n",
       " 'concentrated': 849,\n",
       " 'nhl': 850,\n",
       " \"'re\": 851,\n",
       " 'coleslaw': 852,\n",
       " 'townplace': 853,\n",
       " 'wallpapered': 854,\n",
       " 'forwarned': 855,\n",
       " 'porter': 856,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"rose\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 857,\n",
       " 'cinema': 858,\n",
       " 'reviewer': 859,\n",
       " 'miniscule': 860,\n",
       " 'defo': 861,\n",
       " \"i'ld\": 862,\n",
       " 'leisurely\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 863,\n",
       " 'regularly': 864,\n",
       " 'fluid': 865,\n",
       " 'foreign': 866,\n",
       " 'client': 867,\n",
       " 'beverage': 868,\n",
       " 'madeour': 869,\n",
       " 'easy!!!': 870,\n",
       " 'manageress': 871,\n",
       " 'conditions?': 872,\n",
       " \"companie's\": 873,\n",
       " 'capitan': 874,\n",
       " 'diishes': 875,\n",
       " 'haaaaaa': 876,\n",
       " 'recentely': 877,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"shaft': 878,\n",
       " 'guest?': 879,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"cleaned\\'': 880,\n",
       " 'trash': 881,\n",
       " 'fowl': 882,\n",
       " 'hired': 883,\n",
       " 'varity': 884,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"flat': 885,\n",
       " 'teens\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 886,\n",
       " 'september;': 887,\n",
       " 'restrained': 888,\n",
       " 'gov': 889,\n",
       " 'bench': 890,\n",
       " 'hostess”': 891,\n",
       " 'neightborhood': 892,\n",
       " 'prebooked': 893,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"intimate\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 894,\n",
       " 'applebys': 895,\n",
       " 'dayshift': 896,\n",
       " 'bathrooms!!!': 897,\n",
       " 'humid': 898,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"party': 899,\n",
       " 'difference!!': 900,\n",
       " 'blab': 901,\n",
       " \"gregory's\": 902,\n",
       " 'undergoing': 903,\n",
       " 'execution': 904,\n",
       " 'conditioner;': 905,\n",
       " 'thehotel': 906,\n",
       " 'yankees!!': 907,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"grab': 908,\n",
       " 'run!!!!': 909,\n",
       " 'misrable': 910,\n",
       " 'bumbed': 911,\n",
       " 'grabby': 912,\n",
       " 'conserve': 913,\n",
       " 'sidewalk!': 914,\n",
       " 'convieniently': 915,\n",
       " 'glover': 916,\n",
       " 'staff!': 917,\n",
       " 'oliver': 918,\n",
       " 'uninspiring;': 919,\n",
       " 'hangen': 920,\n",
       " 'generals': 921,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"unofficial\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 922,\n",
       " 'marshmellows': 923,\n",
       " 'pie!': 924,\n",
       " 'then?!': 925,\n",
       " 'donatello’s': 926,\n",
       " 'computerized?': 927,\n",
       " 'pooring': 928,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"english': 929,\n",
       " 'concernned': 930,\n",
       " 'iceberg': 931,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"average': 932,\n",
       " 'lugggage': 933,\n",
       " 'rid': 934,\n",
       " 'barbary': 935,\n",
       " 'giants!': 936,\n",
       " 'accomadations': 937,\n",
       " 'replaced': 938,\n",
       " 'achieving': 939,\n",
       " 'eat?': 940,\n",
       " 'ernesto!': 941,\n",
       " 'reletives': 942,\n",
       " 'youthful': 943,\n",
       " 'juice\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 944,\n",
       " 'climb\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 945,\n",
       " 'chiton': 946,\n",
       " \"courtyard's\": 947,\n",
       " 'etried': 948,\n",
       " 'lapses': 949,\n",
       " '“wow': 950,\n",
       " 'amtrack': 951,\n",
       " 'charges?': 952,\n",
       " 'hesitation!': 953,\n",
       " 'immersion': 954,\n",
       " 'deciding!': 955,\n",
       " 'exploding': 956,\n",
       " '%\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 957,\n",
       " 'iad': 958,\n",
       " 'shack': 959,\n",
       " 'qualm': 960,\n",
       " 'starbucks': 961,\n",
       " 'supperior': 962,\n",
       " 'refrigerating': 963,\n",
       " 'see': 964,\n",
       " 'old;': 965,\n",
       " 'kickoff': 966,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"sale\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"': 967,\n",
       " 'fing': 968,\n",
       " 'panzanos': 969,\n",
       " '\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"boston': 970,\n",
       " 'configuration': 971,\n",
       " \"hubby's\": 972,\n",
       " 'room!': 973,\n",
       " 'bet': 974,\n",
       " 'dad’s': 975,\n",
       " 'church!!': 976,\n",
       " 'divider': 977,\n",
       " 'roudy': 978,\n",
       " 'univ': 979,\n",
       " \"'welcoming\": 980,\n",
       " 'caben': 981,\n",
       " 'cannoy': 982,\n",
       " 'pesticide': 983,\n",
       " 'didn;t': 984,\n",
       " 'novosibirsk': 985,\n",
       " 'there´s': 986,\n",
       " 'nullified': 987,\n",
       " 'rockers': 988,\n",
       " 'khema': 989,\n",
       " 'reatins': 990,\n",
       " 'steep!': 991,\n",
       " '}': 992,\n",
       " \"manhatten'\": 993,\n",
       " 'unanswered': 994,\n",
       " 'curb': 995,\n",
       " 'husband!!!': 996,\n",
       " 'peice': 997,\n",
       " 'deceived': 998,\n",
       " 'hoboes': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = {}\n",
    "for i, word in enumerate(vocab):\n",
    "    word_index[word] = i\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_input_layer(response):\n",
    "    global layer_0\n",
    "    layer_0 *= 0\n",
    "    for word in response.split(\" \"):\n",
    "        layer_0[0][word_index[word]] = 1\n",
    "update_input_layer(responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, responses,labels,hidden_nodes = 15, learning_rate = 0.1):\n",
    "        \"\"\"NeuralNetwork with the given settings\n",
    "        Args:\n",
    "            responses(list) - List of response used for training\n",
    "            labels(list) - List of Good/Bad labels associated with the given responses\n",
    "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
    "            learning_rate(float) - Learning rate to use while training\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.pre_process_data(responses, labels)\n",
    "        \n",
    "        self.init_network(len(self.response_vocab),hidden_nodes, 1, learning_rate)\n",
    "    \n",
    "    \n",
    "    def pre_process_data(self, response, labels):\n",
    "        \n",
    "        response_vocab = set()\n",
    "        for response in responses:\n",
    "            for word in response.split(\" \"):\n",
    "                response_vocab.add(word)\n",
    "\n",
    "        self.response_vocab = list(response_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.response_vocab_size = len(self.response_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.response_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "        \n",
    "    def update_input_layer(self,response):\n",
    "\n",
    "        self.layer_0 *= 0\n",
    "        \n",
    "        for word in response.split(\" \"):\n",
    "            \n",
    "            if(word in self.word2index.keys()):\n",
    "                \n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        \n",
    "        if(label == 'Good'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_responses, training_labels):\n",
    "        \n",
    "        \n",
    "        assert(len(training_responses) == len(training_labels))\n",
    "        \n",
    "        correct_so_far = 0\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_responses)):\n",
    "            \n",
    "            response = training_responses[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #----- Feed Forward -----#\n",
    "            self.update_input_layer(response)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            #----- Back Propagation -----#\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) \n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T)\n",
    "            layer_1_delta = layer_1_error \n",
    "\n",
    "            # Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate \n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate \n",
    "\n",
    "            if(layer_2 >= 0.5 and label == 'Good'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'Bad'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            responses_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_responses)))[:4] \\\n",
    "                             + \"% Speed(responses/sec):\" + str(responses_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            \n",
    "            if(i % 5000 == 0 and i != 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_responses, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        for i in range(len(testing_responses)):\n",
    "            pred = self.run(testing_responses[i])\n",
    "            \n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "        \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            responses_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_responses)))[:4] \\\n",
    "                             + \"% Speed(responses/sec):\" + str(responses_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, response):\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(response.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"Good\"\n",
    "        else:\n",
    "            return \"Bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = NeuralNetwork(responses[:-1000],label[:-1000], learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:17.1% Speed(responses/sec):59.01 #Correct:4108 #Trained:5001 Training Accuracy:82.1%\n",
      "Progress:34.2% Speed(responses/sec):59.23 #Correct:8379 #Trained:10001 Training Accuracy:83.7%\n",
      "Progress:51.4% Speed(responses/sec):59.17 #Correct:12668 #Trained:15001 Training Accuracy:84.4%\n",
      "Progress:68.5% Speed(responses/sec):59.21 #Correct:16997 #Trained:20001 Training Accuracy:84.9%\n",
      "Progress:85.6% Speed(responses/sec):58.83 #Correct:21365 #Trained:25001 Training Accuracy:85.4%\n",
      "Progress:99.9% Speed(responses/sec):58.53 #Correct:25032 #Trained:29172 Training Accuracy:85.8%"
     ]
    }
   ],
   "source": [
    "mlp.train(responses[:-1000],label[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:99.9% Speed(responses/sec):510.7 #Correct:868 #Tested:1000 Testing Accuracy:86.8%"
     ]
    }
   ],
   "source": [
    "mlp.test(responses[-1000:],label[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are able to get a decent model but we can increase the speed of this model, here we have a speed of around 57-59 responses per second. we can increase this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to identify wasteful computation and elminate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_0 = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_0[4] = 1\n",
    "layer_0[7] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.randn(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.26535254,  0.3776197 ,  1.4133905 ,  0.29637708, -1.55469582])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(layer_0, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = [4,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_1 = np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in indices:\n",
    "    layer_1 += (1 * weights[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.26535254,  0.3776197 ,  1.4133905 ,  0.29637708, -1.55469582])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see the same result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork2:\n",
    "    def __init__(self, responses,labels,hidden_nodes = 20, learning_rate = 0.1):\n",
    "        \n",
    "        self.pre_process_data(responses, labels)\n",
    "        \n",
    "        self.init_network(len(self.response_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, responses, labels):\n",
    "        \n",
    "        response_vocab = set()\n",
    "        for response in responses:\n",
    "            for word in response.split(\" \"):\n",
    "                response_vocab.add(word)\n",
    "\n",
    "        self.response_vocab = list(response_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        self.response_vocab_size = len(self.response_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.response_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "\n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        \n",
    "        self.layer_1 = np.zeros((1,hidden_nodes))\n",
    "    \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'Good'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "   \n",
    "    def train(self, training_responses_raw, training_labels):\n",
    "\n",
    "        training_responses = list()\n",
    "        for response in training_responses_raw:\n",
    "            indices = set()\n",
    "            for word in response.split(\" \"):\n",
    "                if(word in self.word2index.keys()):\n",
    "                    indices.add(self.word2index[word])\n",
    "            training_responses.append(list(indices))\n",
    "\n",
    "        \n",
    "        assert(len(training_responses) == len(training_labels))\n",
    "                \n",
    "        correct_so_far = 0\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(len(training_responses)):\n",
    "            \n",
    "            response = training_responses[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            self.layer_1 *= 0\n",
    "            for index in response:\n",
    "                self.layer_1 += self.weights_0_1[index]\n",
    "\n",
    "            layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))            \n",
    "            \n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label)\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T)\n",
    "            layer_1_delta = layer_1_error\n",
    "\n",
    "            \n",
    "            self.weights_1_2 -= self.layer_1.T.dot(layer_2_delta) * self.learning_rate\n",
    "            \n",
    "            \n",
    "            for index in response:\n",
    "                self.weights_0_1[index] -= layer_1_delta[0] * self.learning_rate \n",
    "\n",
    "            if(layer_2 >= 0.5 and label == 'Good'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'Bad'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            responses_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_responses)))[:4] \\\n",
    "                             + \"% Speed(response/sec):\" + str(responses_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_responses, testing_labels):\n",
    "        \n",
    "        correct = 0\n",
    "        start = time.time()\n",
    " \n",
    "        for i in range(len(testing_responses)):\n",
    "            pred = self.run(testing_responses[i])\n",
    "\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            responses_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_responses)))[:4] \\\n",
    "                             + \"% Speed(responses/sec):\" + str(responses_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "       \n",
    "    \n",
    "    def run(self, response):\n",
    "        \n",
    "        self.layer_1 *= 0\n",
    "        unique_indices = set()\n",
    "        for word in response.lower().split(\" \"):\n",
    "            if word in self.word2index.keys():\n",
    "                unique_indices.add(self.word2index[word])\n",
    "        for index in unique_indices:\n",
    "            self.layer_1 += self.weights_0_1[index]\n",
    "        \n",
    "        layer_2 = self.sigmoid(self.layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"Good\"\n",
    "        else:\n",
    "            return \"Bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp2 = NeuralNetwork2(responses[:-200],label[:-200], learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(response/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "Progress:8.34% Speed(response/sec):537.1 #Correct:2014 #Trained:2501 Training Accuracy:80.5%\n",
      "Progress:16.6% Speed(response/sec):510.6 #Correct:4088 #Trained:5001 Training Accuracy:81.7%\n",
      "Progress:25.0% Speed(response/sec):505.3 #Correct:6232 #Trained:7501 Training Accuracy:83.0%\n",
      "Progress:33.3% Speed(response/sec):499.4 #Correct:8335 #Trained:10001 Training Accuracy:83.3%\n",
      "Progress:41.7% Speed(response/sec):499.9 #Correct:10473 #Trained:12501 Training Accuracy:83.7%\n",
      "Progress:50.0% Speed(response/sec):495.3 #Correct:12590 #Trained:15001 Training Accuracy:83.9%\n",
      "Progress:58.3% Speed(response/sec):493.1 #Correct:14701 #Trained:17501 Training Accuracy:84.0%\n",
      "Progress:66.7% Speed(response/sec):489.3 #Correct:16868 #Trained:20001 Training Accuracy:84.3%\n",
      "Progress:75.0% Speed(response/sec):486.4 #Correct:19046 #Trained:22501 Training Accuracy:84.6%\n",
      "Progress:83.4% Speed(response/sec):484.8 #Correct:21217 #Trained:25001 Training Accuracy:84.8%\n",
      "Progress:91.7% Speed(response/sec):487.1 #Correct:23403 #Trained:27501 Training Accuracy:85.0%\n",
      "Progress:99.9% Speed(response/sec):487.8 #Correct:25552 #Trained:29972 Training Accuracy:85.2%"
     ]
    }
   ],
   "source": [
    "mlp2.train(responses[:-200],label[:-200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:0.0% Speed(responses/sec):0.0 #Correct:1 #Tested:1 Testing Accuracy:100.%\r",
      "Progress:0.5% Speed(responses/sec):333.3 #Correct:2 #Tested:2 Testing Accuracy:100.%\r",
      "Progress:1.0% Speed(responses/sec):499.9 #Correct:3 #Tested:3 Testing Accuracy:100.%\r",
      "Progress:1.5% Speed(responses/sec):599.9 #Correct:4 #Tested:4 Testing Accuracy:100.%\r",
      "Progress:2.0% Speed(responses/sec):499.9 #Correct:5 #Tested:5 Testing Accuracy:100.%\r",
      "Progress:2.5% Speed(responses/sec):555.5 #Correct:6 #Tested:6 Testing Accuracy:100.%\r",
      "Progress:3.0% Speed(responses/sec):599.9 #Correct:7 #Tested:7 Testing Accuracy:100.%\r",
      "Progress:3.5% Speed(responses/sec):538.4 #Correct:7 #Tested:8 Testing Accuracy:87.5%\r",
      "Progress:4.0% Speed(responses/sec):571.3 #Correct:8 #Tested:9 Testing Accuracy:88.8%\r",
      "Progress:4.5% Speed(responses/sec):562.4 #Correct:9 #Tested:10 Testing Accuracy:90.0%\r",
      "Progress:5.0% Speed(responses/sec):555.5 #Correct:9 #Tested:11 Testing Accuracy:81.8%\r",
      "Progress:5.5% Speed(responses/sec):578.9 #Correct:10 #Tested:12 Testing Accuracy:83.3%\r",
      "Progress:6.0% Speed(responses/sec):599.9 #Correct:11 #Tested:13 Testing Accuracy:84.6%\r",
      "Progress:6.5% Speed(responses/sec):619.0 #Correct:11 #Tested:14 Testing Accuracy:78.5%\r",
      "Progress:7.0% Speed(responses/sec):608.6 #Correct:12 #Tested:15 Testing Accuracy:80.0%\r",
      "Progress:7.5% Speed(responses/sec):599.9 #Correct:13 #Tested:16 Testing Accuracy:81.2%\r",
      "Progress:8.0% Speed(responses/sec):615.3 #Correct:14 #Tested:17 Testing Accuracy:82.3%\r",
      "Progress:8.5% Speed(responses/sec):629.5 #Correct:15 #Tested:18 Testing Accuracy:83.3%\r",
      "Progress:9.0% Speed(responses/sec):642.8 #Correct:16 #Tested:19 Testing Accuracy:84.2%\r",
      "Progress:9.5% Speed(responses/sec):633.2 #Correct:17 #Tested:20 Testing Accuracy:85.0%\r",
      "Progress:10.0% Speed(responses/sec):645.1 #Correct:18 #Tested:21 Testing Accuracy:85.7%\r",
      "Progress:10.5% Speed(responses/sec):636.3 #Correct:19 #Tested:22 Testing Accuracy:86.3%\r",
      "Progress:11.0% Speed(responses/sec):628.5 #Correct:20 #Tested:23 Testing Accuracy:86.9%\r",
      "Progress:11.5% Speed(responses/sec):638.8 #Correct:21 #Tested:24 Testing Accuracy:87.5%\r",
      "Progress:12.0% Speed(responses/sec):648.6 #Correct:22 #Tested:25 Testing Accuracy:88.0%\r",
      "Progress:12.5% Speed(responses/sec):640.9 #Correct:23 #Tested:26 Testing Accuracy:88.4%\r",
      "Progress:13.0% Speed(responses/sec):649.9 #Correct:24 #Tested:27 Testing Accuracy:88.8%\r",
      "Progress:13.5% Speed(responses/sec):642.8 #Correct:25 #Tested:28 Testing Accuracy:89.2%\r",
      "Progress:14.0% Speed(responses/sec):651.1 #Correct:25 #Tested:29 Testing Accuracy:86.2%\r",
      "Progress:14.5% Speed(responses/sec):659.0 #Correct:26 #Tested:30 Testing Accuracy:86.6%\r",
      "Progress:15.0% Speed(responses/sec):666.6 #Correct:27 #Tested:31 Testing Accuracy:87.0%\r",
      "Progress:15.5% Speed(responses/sec):673.8 #Correct:28 #Tested:32 Testing Accuracy:87.5%\r",
      "Progress:16.0% Speed(responses/sec):653.0 #Correct:28 #Tested:33 Testing Accuracy:84.8%\r",
      "Progress:16.5% Speed(responses/sec):659.9 #Correct:29 #Tested:34 Testing Accuracy:85.2%\r",
      "Progress:17.0% Speed(responses/sec):666.6 #Correct:30 #Tested:35 Testing Accuracy:85.7%\r",
      "Progress:17.5% Speed(responses/sec):673.0 #Correct:31 #Tested:36 Testing Accuracy:86.1%\r",
      "Progress:18.0% Speed(responses/sec):679.2 #Correct:32 #Tested:37 Testing Accuracy:86.4%\r",
      "Progress:18.5% Speed(responses/sec):660.6 #Correct:32 #Tested:38 Testing Accuracy:84.2%\r",
      "Progress:19.0% Speed(responses/sec):666.6 #Correct:33 #Tested:39 Testing Accuracy:84.6%\r",
      "Progress:19.5% Speed(responses/sec):660.9 #Correct:34 #Tested:40 Testing Accuracy:85.0%\r",
      "Progress:20.0% Speed(responses/sec):655.7 #Correct:35 #Tested:41 Testing Accuracy:85.3%\r",
      "Progress:20.5% Speed(responses/sec):661.2 #Correct:36 #Tested:42 Testing Accuracy:85.7%\r",
      "Progress:21.0% Speed(responses/sec):656.2 #Correct:37 #Tested:43 Testing Accuracy:86.0%\r",
      "Progress:21.5% Speed(responses/sec):661.5 #Correct:38 #Tested:44 Testing Accuracy:86.3%\r",
      "Progress:22.0% Speed(responses/sec):666.6 #Correct:39 #Tested:45 Testing Accuracy:86.6%\r",
      "Progress:22.5% Speed(responses/sec):671.6 #Correct:40 #Tested:46 Testing Accuracy:86.9%\r",
      "Progress:23.0% Speed(responses/sec):686.5 #Correct:41 #Tested:47 Testing Accuracy:87.2%\r",
      "Progress:23.5% Speed(responses/sec):671.3 #Correct:42 #Tested:48 Testing Accuracy:87.5%\r",
      "Progress:24.0% Speed(responses/sec):676.0 #Correct:43 #Tested:49 Testing Accuracy:87.7%\r",
      "Progress:24.5% Speed(responses/sec):662.1 #Correct:44 #Tested:50 Testing Accuracy:88.0%\r",
      "Progress:25.0% Speed(responses/sec):666.6 #Correct:45 #Tested:51 Testing Accuracy:88.2%\r",
      "Progress:25.5% Speed(responses/sec):662.3 #Correct:46 #Tested:52 Testing Accuracy:88.4%\r",
      "Progress:26.0% Speed(responses/sec):658.1 #Correct:47 #Tested:53 Testing Accuracy:88.6%\r",
      "Progress:26.5% Speed(responses/sec):654.2 #Correct:48 #Tested:54 Testing Accuracy:88.8%\r",
      "Progress:27.0% Speed(responses/sec):658.4 #Correct:49 #Tested:55 Testing Accuracy:89.0%\r",
      "Progress:27.5% Speed(responses/sec):670.6 #Correct:50 #Tested:56 Testing Accuracy:89.2%\r",
      "Progress:28.0% Speed(responses/sec):636.3 #Correct:50 #Tested:57 Testing Accuracy:87.7%\r",
      "Progress:28.5% Speed(responses/sec):640.4 #Correct:51 #Tested:58 Testing Accuracy:87.9%\r",
      "Progress:29.0% Speed(responses/sec):630.3 #Correct:52 #Tested:59 Testing Accuracy:88.1%\r",
      "Progress:29.5% Speed(responses/sec):627.6 #Correct:53 #Tested:60 Testing Accuracy:88.3%\r",
      "Progress:30.0% Speed(responses/sec):624.9 #Correct:54 #Tested:61 Testing Accuracy:88.5%\r",
      "Progress:30.5% Speed(responses/sec):616.1 #Correct:54 #Tested:62 Testing Accuracy:87.0%\r",
      "Progress:31.0% Speed(responses/sec):613.8 #Correct:55 #Tested:63 Testing Accuracy:87.3%\r",
      "Progress:31.5% Speed(responses/sec):617.6 #Correct:56 #Tested:64 Testing Accuracy:87.5%\r",
      "Progress:32.0% Speed(responses/sec):615.3 #Correct:57 #Tested:65 Testing Accuracy:87.6%\r",
      "Progress:32.5% Speed(responses/sec):613.1 #Correct:58 #Tested:66 Testing Accuracy:87.8%\r",
      "Progress:33.0% Speed(responses/sec):616.7 #Correct:59 #Tested:67 Testing Accuracy:88.0%\r",
      "Progress:33.5% Speed(responses/sec):620.3 #Correct:60 #Tested:68 Testing Accuracy:88.2%\r",
      "Progress:34.0% Speed(responses/sec):607.1 #Correct:61 #Tested:69 Testing Accuracy:88.4%\r",
      "Progress:34.5% Speed(responses/sec):616.0 #Correct:62 #Tested:70 Testing Accuracy:88.5%\r",
      "Progress:35.0% Speed(responses/sec):613.9 #Correct:63 #Tested:71 Testing Accuracy:88.7%\r",
      "Progress:35.5% Speed(responses/sec):617.3 #Correct:63 #Tested:72 Testing Accuracy:87.5%\r",
      "Progress:36.0% Speed(responses/sec):620.6 #Correct:63 #Tested:73 Testing Accuracy:86.3%\r",
      "Progress:36.5% Speed(responses/sec):629.2 #Correct:64 #Tested:74 Testing Accuracy:86.4%\r",
      "Progress:37.0% Speed(responses/sec):621.8 #Correct:65 #Tested:75 Testing Accuracy:86.6%\r",
      "Progress:37.5% Speed(responses/sec):624.9 #Correct:66 #Tested:76 Testing Accuracy:86.8%\r",
      "Progress:38.0% Speed(responses/sec):628.0 #Correct:67 #Tested:77 Testing Accuracy:87.0%\r",
      "Progress:38.5% Speed(responses/sec):631.1 #Correct:68 #Tested:78 Testing Accuracy:87.1%\r",
      "Progress:39.0% Speed(responses/sec):609.3 #Correct:69 #Tested:79 Testing Accuracy:87.3%\r",
      "Progress:39.5% Speed(responses/sec):612.3 #Correct:70 #Tested:80 Testing Accuracy:87.5%\r",
      "Progress:40.0% Speed(responses/sec):615.3 #Correct:71 #Tested:81 Testing Accuracy:87.6%\r",
      "Progress:40.5% Speed(responses/sec):613.6 #Correct:72 #Tested:82 Testing Accuracy:87.8%\r",
      "Progress:41.0% Speed(responses/sec):616.5 #Correct:73 #Tested:83 Testing Accuracy:87.9%\r",
      "Progress:41.5% Speed(responses/sec):614.7 #Correct:74 #Tested:84 Testing Accuracy:88.0%\r",
      "Progress:42.0% Speed(responses/sec):617.6 #Correct:75 #Tested:85 Testing Accuracy:88.2%\r",
      "Progress:42.5% Speed(responses/sec):620.4 #Correct:76 #Tested:86 Testing Accuracy:88.3%\r",
      "Progress:43.0% Speed(responses/sec):605.5 #Correct:77 #Tested:87 Testing Accuracy:88.5%\r",
      "Progress:43.5% Speed(responses/sec):604.1 #Correct:78 #Tested:88 Testing Accuracy:88.6%\r",
      "Progress:44.0% Speed(responses/sec):611.0 #Correct:78 #Tested:89 Testing Accuracy:87.6%\r",
      "Progress:44.5% Speed(responses/sec):609.5 #Correct:79 #Tested:90 Testing Accuracy:87.7%\r",
      "Progress:45.0% Speed(responses/sec):608.0 #Correct:80 #Tested:91 Testing Accuracy:87.9%\r",
      "Progress:45.5% Speed(responses/sec):614.8 #Correct:81 #Tested:92 Testing Accuracy:88.0%\r",
      "Progress:46.0% Speed(responses/sec):617.4 #Correct:82 #Tested:93 Testing Accuracy:88.1%\r",
      "Progress:46.5% Speed(responses/sec):611.8 #Correct:83 #Tested:94 Testing Accuracy:88.2%\r",
      "Progress:47.0% Speed(responses/sec):606.4 #Correct:84 #Tested:95 Testing Accuracy:88.4%\r",
      "Progress:47.5% Speed(responses/sec):608.9 #Correct:85 #Tested:96 Testing Accuracy:88.5%\r",
      "Progress:48.0% Speed(responses/sec):607.5 #Correct:86 #Tested:97 Testing Accuracy:88.6%\r",
      "Progress:48.5% Speed(responses/sec):610.0 #Correct:87 #Tested:98 Testing Accuracy:88.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress:49.0% Speed(responses/sec):608.6 #Correct:88 #Tested:99 Testing Accuracy:88.8%\r",
      "Progress:49.5% Speed(responses/sec):607.3 #Correct:89 #Tested:100 Testing Accuracy:89.0%\r",
      "Progress:50.0% Speed(responses/sec):606.0 #Correct:90 #Tested:101 Testing Accuracy:89.1%\r",
      "Progress:50.5% Speed(responses/sec):608.3 #Correct:90 #Tested:102 Testing Accuracy:88.2%\r",
      "Progress:51.0% Speed(responses/sec):607.1 #Correct:91 #Tested:103 Testing Accuracy:88.3%\r",
      "Progress:51.5% Speed(responses/sec):605.8 #Correct:92 #Tested:104 Testing Accuracy:88.4%\r",
      "Progress:52.0% Speed(responses/sec):604.6 #Correct:93 #Tested:105 Testing Accuracy:88.5%\r",
      "Progress:52.5% Speed(responses/sec):603.4 #Correct:93 #Tested:106 Testing Accuracy:87.7%\r",
      "Progress:53.0% Speed(responses/sec):595.4 #Correct:94 #Tested:107 Testing Accuracy:87.8%\r",
      "Progress:53.5% Speed(responses/sec):597.7 #Correct:95 #Tested:108 Testing Accuracy:87.9%\r",
      "Progress:54.0% Speed(responses/sec):599.9 #Correct:96 #Tested:109 Testing Accuracy:88.0%\r",
      "Progress:54.5% Speed(responses/sec):602.1 #Correct:97 #Tested:110 Testing Accuracy:88.1%\r",
      "Progress:55.0% Speed(responses/sec):597.7 #Correct:98 #Tested:111 Testing Accuracy:88.2%\r",
      "Progress:55.5% Speed(responses/sec):596.7 #Correct:99 #Tested:112 Testing Accuracy:88.3%\r",
      "Progress:56.0% Speed(responses/sec):595.7 #Correct:100 #Tested:113 Testing Accuracy:88.4%\r",
      "Progress:56.5% Speed(responses/sec):597.8 #Correct:101 #Tested:114 Testing Accuracy:88.5%\r",
      "Progress:57.0% Speed(responses/sec):599.9 #Correct:102 #Tested:115 Testing Accuracy:88.6%\r",
      "Progress:57.5% Speed(responses/sec):602.0 #Correct:102 #Tested:116 Testing Accuracy:87.9%\r",
      "Progress:58.0% Speed(responses/sec):607.2 #Correct:103 #Tested:117 Testing Accuracy:88.0%\r",
      "Progress:58.5% Speed(responses/sec):609.3 #Correct:104 #Tested:118 Testing Accuracy:88.1%\r",
      "Progress:59.0% Speed(responses/sec):608.2 #Correct:105 #Tested:119 Testing Accuracy:88.2%\r",
      "Progress:59.5% Speed(responses/sec):610.2 #Correct:106 #Tested:120 Testing Accuracy:88.3%\r",
      "Progress:60.0% Speed(responses/sec):612.2 #Correct:107 #Tested:121 Testing Accuracy:88.4%\r",
      "Progress:60.5% Speed(responses/sec):604.9 #Correct:108 #Tested:122 Testing Accuracy:88.5%\r",
      "Progress:61.0% Speed(responses/sec):603.9 #Correct:108 #Tested:123 Testing Accuracy:87.8%\r",
      "Progress:61.5% Speed(responses/sec):599.9 #Correct:109 #Tested:124 Testing Accuracy:87.9%\r",
      "Progress:62.0% Speed(responses/sec):601.9 #Correct:110 #Tested:125 Testing Accuracy:88.0%\r",
      "Progress:62.5% Speed(responses/sec):603.8 #Correct:111 #Tested:126 Testing Accuracy:88.0%\r",
      "Progress:63.0% Speed(responses/sec):602.8 #Correct:112 #Tested:127 Testing Accuracy:88.1%\r",
      "Progress:63.5% Speed(responses/sec):604.7 #Correct:113 #Tested:128 Testing Accuracy:88.2%\r",
      "Progress:64.0% Speed(responses/sec):603.7 #Correct:114 #Tested:129 Testing Accuracy:88.3%\r",
      "Progress:64.5% Speed(responses/sec):599.9 #Correct:115 #Tested:130 Testing Accuracy:88.4%\r",
      "Progress:65.0% Speed(responses/sec):580.3 #Correct:115 #Tested:131 Testing Accuracy:87.7%\r",
      "Progress:65.5% Speed(responses/sec):582.1 #Correct:115 #Tested:132 Testing Accuracy:87.1%\r",
      "Progress:66.0% Speed(responses/sec):578.9 #Correct:116 #Tested:133 Testing Accuracy:87.2%\r",
      "Progress:66.5% Speed(responses/sec):580.7 #Correct:117 #Tested:134 Testing Accuracy:87.3%\r",
      "Progress:67.0% Speed(responses/sec):572.6 #Correct:118 #Tested:135 Testing Accuracy:87.4%\r",
      "Progress:67.5% Speed(responses/sec):574.4 #Correct:119 #Tested:136 Testing Accuracy:87.5%\r",
      "Progress:68.0% Speed(responses/sec):571.3 #Correct:120 #Tested:137 Testing Accuracy:87.5%\r",
      "Progress:68.5% Speed(responses/sec):573.1 #Correct:120 #Tested:138 Testing Accuracy:86.9%\r",
      "Progress:69.0% Speed(responses/sec):574.9 #Correct:121 #Tested:139 Testing Accuracy:87.0%\r",
      "Progress:69.5% Speed(responses/sec):574.3 #Correct:122 #Tested:140 Testing Accuracy:87.1%\r",
      "Progress:70.0% Speed(responses/sec):576.0 #Correct:123 #Tested:141 Testing Accuracy:87.2%\r",
      "Progress:70.5% Speed(responses/sec):573.1 #Correct:124 #Tested:142 Testing Accuracy:87.3%\r",
      "Progress:71.0% Speed(responses/sec):574.8 #Correct:124 #Tested:143 Testing Accuracy:86.7%\r",
      "Progress:71.5% Speed(responses/sec):574.2 #Correct:124 #Tested:144 Testing Accuracy:86.1%\r",
      "Progress:72.0% Speed(responses/sec):571.3 #Correct:125 #Tested:145 Testing Accuracy:86.2%\r",
      "Progress:72.5% Speed(responses/sec):570.8 #Correct:126 #Tested:146 Testing Accuracy:86.3%\r",
      "Progress:73.0% Speed(responses/sec):570.2 #Correct:127 #Tested:147 Testing Accuracy:86.3%\r",
      "Progress:73.5% Speed(responses/sec):571.9 #Correct:127 #Tested:148 Testing Accuracy:85.8%\r",
      "Progress:74.0% Speed(responses/sec):573.6 #Correct:128 #Tested:149 Testing Accuracy:85.9%\r",
      "Progress:74.5% Speed(responses/sec):575.2 #Correct:128 #Tested:150 Testing Accuracy:85.3%\r",
      "Progress:75.0% Speed(responses/sec):576.8 #Correct:129 #Tested:151 Testing Accuracy:85.4%\r",
      "Progress:75.5% Speed(responses/sec):574.1 #Correct:130 #Tested:152 Testing Accuracy:85.5%\r",
      "Progress:76.0% Speed(responses/sec):573.5 #Correct:131 #Tested:153 Testing Accuracy:85.6%\r",
      "Progress:76.5% Speed(responses/sec):573.0 #Correct:132 #Tested:154 Testing Accuracy:85.7%\r",
      "Progress:77.0% Speed(responses/sec):574.5 #Correct:133 #Tested:155 Testing Accuracy:85.8%\r",
      "Progress:77.5% Speed(responses/sec):574.0 #Correct:134 #Tested:156 Testing Accuracy:85.8%\r",
      "Progress:78.0% Speed(responses/sec):575.6 #Correct:135 #Tested:157 Testing Accuracy:85.9%\r",
      "Progress:78.5% Speed(responses/sec):575.0 #Correct:136 #Tested:158 Testing Accuracy:86.0%\r",
      "Progress:79.0% Speed(responses/sec):574.5 #Correct:137 #Tested:159 Testing Accuracy:86.1%\r",
      "Progress:79.5% Speed(responses/sec):571.9 #Correct:138 #Tested:160 Testing Accuracy:86.2%\r",
      "Progress:80.0% Speed(responses/sec):573.4 #Correct:139 #Tested:161 Testing Accuracy:86.3%\r",
      "Progress:80.5% Speed(responses/sec):574.9 #Correct:140 #Tested:162 Testing Accuracy:86.4%\r",
      "Progress:81.0% Speed(responses/sec):578.5 #Correct:141 #Tested:163 Testing Accuracy:86.5%\r",
      "Progress:81.5% Speed(responses/sec):577.9 #Correct:142 #Tested:164 Testing Accuracy:86.5%\r",
      "Progress:82.0% Speed(responses/sec):579.4 #Correct:143 #Tested:165 Testing Accuracy:86.6%\r",
      "Progress:82.5% Speed(responses/sec):583.0 #Correct:143 #Tested:166 Testing Accuracy:86.1%\r",
      "Progress:83.0% Speed(responses/sec):584.4 #Correct:144 #Tested:167 Testing Accuracy:86.2%\r",
      "Progress:83.5% Speed(responses/sec):585.9 #Correct:144 #Tested:168 Testing Accuracy:85.7%\r",
      "Progress:84.0% Speed(responses/sec):587.3 #Correct:145 #Tested:169 Testing Accuracy:85.7%\r",
      "Progress:84.5% Speed(responses/sec):588.8 #Correct:146 #Tested:170 Testing Accuracy:85.8%\r",
      "Progress:85.0% Speed(responses/sec):590.2 #Correct:147 #Tested:171 Testing Accuracy:85.9%\r",
      "Progress:85.5% Speed(responses/sec):583.5 #Correct:148 #Tested:172 Testing Accuracy:86.0%\r",
      "Progress:86.0% Speed(responses/sec):585.0 #Correct:149 #Tested:173 Testing Accuracy:86.1%\r",
      "Progress:86.5% Speed(responses/sec):586.4 #Correct:150 #Tested:174 Testing Accuracy:86.2%\r",
      "Progress:87.0% Speed(responses/sec):585.8 #Correct:151 #Tested:175 Testing Accuracy:86.2%\r",
      "Progress:87.5% Speed(responses/sec):587.2 #Correct:152 #Tested:176 Testing Accuracy:86.3%\r",
      "Progress:88.0% Speed(responses/sec):586.6 #Correct:153 #Tested:177 Testing Accuracy:86.4%\r",
      "Progress:88.5% Speed(responses/sec):588.0 #Correct:154 #Tested:178 Testing Accuracy:86.5%\r",
      "Progress:89.0% Speed(responses/sec):585.4 #Correct:155 #Tested:179 Testing Accuracy:86.5%\r",
      "Progress:89.5% Speed(responses/sec):584.9 #Correct:156 #Tested:180 Testing Accuracy:86.6%\r",
      "Progress:90.0% Speed(responses/sec):586.2 #Correct:157 #Tested:181 Testing Accuracy:86.7%\r",
      "Progress:90.5% Speed(responses/sec):585.7 #Correct:158 #Tested:182 Testing Accuracy:86.8%\r",
      "Progress:91.0% Speed(responses/sec):583.2 #Correct:158 #Tested:183 Testing Accuracy:86.3%\r",
      "Progress:91.5% Speed(responses/sec):582.7 #Correct:158 #Tested:184 Testing Accuracy:85.8%\r",
      "Progress:92.0% Speed(responses/sec):584.0 #Correct:159 #Tested:185 Testing Accuracy:85.9%\r",
      "Progress:92.5% Speed(responses/sec):585.4 #Correct:160 #Tested:186 Testing Accuracy:86.0%\r",
      "Progress:93.0% Speed(responses/sec):586.7 #Correct:161 #Tested:187 Testing Accuracy:86.0%\r",
      "Progress:93.5% Speed(responses/sec):588.0 #Correct:162 #Tested:188 Testing Accuracy:86.1%\r",
      "Progress:94.0% Speed(responses/sec):589.3 #Correct:163 #Tested:189 Testing Accuracy:86.2%\r",
      "Progress:94.5% Speed(responses/sec):588.7 #Correct:164 #Tested:190 Testing Accuracy:86.3%\r",
      "Progress:95.0% Speed(responses/sec):590.0 #Correct:165 #Tested:191 Testing Accuracy:86.3%\r",
      "Progress:95.5% Speed(responses/sec):589.4 #Correct:166 #Tested:192 Testing Accuracy:86.4%\r",
      "Progress:96.0% Speed(responses/sec):592.5 #Correct:167 #Tested:193 Testing Accuracy:86.5%\r",
      "Progress:96.5% Speed(responses/sec):593.8 #Correct:168 #Tested:194 Testing Accuracy:86.5%\r",
      "Progress:97.0% Speed(responses/sec):595.0 #Correct:169 #Tested:195 Testing Accuracy:86.6%\r",
      "Progress:97.5% Speed(responses/sec):594.4 #Correct:170 #Tested:196 Testing Accuracy:86.7%\r",
      "Progress:98.0% Speed(responses/sec):595.7 #Correct:171 #Tested:197 Testing Accuracy:86.8%\r",
      "Progress:98.5% Speed(responses/sec):596.9 #Correct:172 #Tested:198 Testing Accuracy:86.8%\r",
      "Progress:99.0% Speed(responses/sec):598.1 #Correct:173 #Tested:199 Testing Accuracy:86.9%\r",
      "Progress:99.5% Speed(responses/sec):599.3 #Correct:174 #Tested:200 Testing Accuracy:87.0%"
     ]
    }
   ],
   "source": [
    "mlp2.test(responses[-200:],label[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.run(\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bad'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.run(\"filthy hotel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we have almost the same accuracy but responses/sec have increased from around 50 to somewhere around 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv', delimiter='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9602</td>\n",
       "      <td>A friend and I stayed in this hotel when we we...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8749</td>\n",
       "      <td>I enjoy staying here when I have early flights...</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15500</td>\n",
       "      <td>I stopped off in Seattle during a train tour o...</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5495</td>\n",
       "      <td>I have stayed at this hotel - or - times now f...</td>\n",
       "      <td>Mozilla Firefox</td>\n",
       "      <td>Desktop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18570</td>\n",
       "      <td>Excellent location with hop on hop off city tr...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0     9602  A friend and I stayed in this hotel when we we...   \n",
       "1     8749  I enjoy staying here when I have early flights...   \n",
       "2    15500  I stopped off in Seattle during a train tour o...   \n",
       "3     5495  I have stayed at this hotel - or - times now f...   \n",
       "4    18570  Excellent location with hop on hop off city tr...   \n",
       "\n",
       "      Browser_Used Device_Used  \n",
       "0             Edge     Desktop  \n",
       "1    Google Chrome      Mobile  \n",
       "2           Chrome      Mobile  \n",
       "3  Mozilla Firefox     Desktop  \n",
       "4             Edge      Mobile  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"sample_submission.csv\", delimiter=\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9602</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5495</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18570</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Is_Response\n",
       "0     9602          NaN\n",
       "1     8749          NaN\n",
       "2    15500          NaN\n",
       "3     5495          NaN\n",
       "4    18570          NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_response = []\n",
    "test_desc = list(test_df[\"Description\"])\n",
    "test_userid = list(test_df[\"User_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = [':', \"(\", \")\", \"-\", \".\", \"\\n\", \",\"]\n",
    "\n",
    "for m,i in enumerate(test_desc):\n",
    "    for j in noise:\n",
    "        test_desc[m] = test_desc[m].replace(j,\" \")\n",
    "    test_desc[m] = test_desc[m].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in test_desc:\n",
    "    test_response.append(mlp2.run(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Bad',\n",
       " 'Bad',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good',\n",
       " 'Good']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_response[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission_df = pd.DataFrame({\"User_ID\": test_userid, \"Is_Response\": test_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Response</th>\n",
       "      <th>User_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>9602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>8749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>15500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>5495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>18570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Is_Response  User_ID\n",
       "0        Good     9602\n",
       "1        Good     8749\n",
       "2        Good    15500\n",
       "3        Good     5495\n",
       "4        Good    18570"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' correctly).\\nAll in all, it was a good, safe, affordable hotel. I would definitely stay there again.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Description[0][-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' correctly   all in all  it was a good  safe  affordable hotel  i would definitely stay there again '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_desc[0][-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False, sep=\"~\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_sub = pd.read_csv(\"submission.csv\", delimiter=\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Is_Response</th>\n",
       "      <th>User_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good</td>\n",
       "      <td>9602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good</td>\n",
       "      <td>8749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>15500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>5495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>18570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Is_Response  User_ID\n",
       "0        Good     9602\n",
       "1        Good     8749\n",
       "2        Good    15500\n",
       "3        Good     5495\n",
       "4        Good    18570"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9602</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5495</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18570</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Is_Response\n",
       "0     9602          NaN\n",
       "1     8749          NaN\n",
       "2    15500          NaN\n",
       "3     5495          NaN\n",
       "4    18570          NaN"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
